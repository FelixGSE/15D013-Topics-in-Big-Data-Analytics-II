"\n",
"------------------------------------","\n",
"************************************","\n"
)
}
final.output = list( mse = global.mse.svm, gamma = global.gam.svm, cost = global.cos.svm  )
return( final.output )
}
# Find best SVM
svm.model <- smv.lag.grid.search(ratio.log,
splog,
response.name = "SP500",
lag.array     = 1:12,
include.self  = FALSE,
gamma.array   = c(seq(0.01,1,0.1),10),
cost.array    = c(seq(0.01,1,0.1),100),
data.split    = 0.80,
inner.trace   = FALSE,
outer.trace   = TRUE,
final.trace   = TRUE
)
svm.model <- smv.lag.grid.search(ratio.log,
splog,
response.name = "SP500",
lag.array     = 1:12,
gamma.array   = c(seq(0.01,1,0.1),10),
cost.array    = c(seq(0.01,1,0.1),100),
data.split    = 0.80,
inner.trace   = FALSE,
outer.trace   = TRUE,
final.trace   = TRUE
)
is.na(predictor.data)
predictor.data <- cbind(splog[1:(len-1)],ratio.log[2:len,])[-1,]
predictor.data <- cbind(splog[1:(len-1)],ratio.log[2:len,])[-1,]
}
is.na(predictor.data)
predictor.data[is.na(predictor.data)] <- 0
is.na(predictor.data)
svm.model <- smv.lag.grid.search(predictor.data,
splog,
response.name = "SP500",
lag.array     = 1:12,
include.self  = FALSE,
gamma.array   = c(seq(0.01,1,0.1),10),
cost.array    = c(seq(0.01,1,0.1),100),
data.split    = 0.80,
inner.trace   = FALSE,
outer.trace   = TRUE,
final.trace   = TRUE
)
# ------------------------------------------------------------------------------
# Compute returns from
# ------------------------------------------------------------------------------
returns <- function( series, log = FALSE, abs = FALSE, center = FALSE, scale = FALSE ){
# Indentify class of series
series.class <- class( series )
# Depending on object class define lagged and future series
if( series.class == "data.frame" | series.class == "matrix" ){
# Compute dimensions of input series
N      <- nrow( series )
# Compute ahead and lagged values
future <- series[ 2:N, ]
past   <- series[ 1:( N - 1), ]
} else {
# Compute length of series in case of class numeric
N      <- length( series )
# Compute ahead and lagged values
future <- series[ 2:N ]
past   <- series[ 1:( N - 1) ]
}
# Compute returns
returns <- (future / past) - 1
# Run additional options
if( log == TRUE ){
returns <- returns + 1
returns <- log( returns )
}
if( abs == TRUE ){
returns <- abs( returns )
}
# Final adjustments
returns <- as.data.frame( scale( returns, center = center, scale = scale ) )
# return modified prices series
return( returns )
}
# ------------------------------------------------------------------------------
# Compute a data set with lagged data
# ------------------------------------------------------------------------------
lagged.data.set <- function( nlag, data ){
# Initialize dataframe and colnames
data <- as.data.frame(data)
lagged.data <- data
colnames    <- colnames( data )
# Run lagged columns according to arguments
for ( lag in 1:nlag ){
# Compute lagged values and append to data frame
lagged.cols  <- data[ 1:(nrow(data) - lag ),colnames]
all.colnames <- colnames(lagged.data)
lagged.data  <- lagged.data[2:nrow(lagged.data),]
lagged.data  <- cbind(lagged.data, lagged.cols)
# Update column names
colnames(lagged.data) <- append(all.colnames, sapply(colnames, paste0, paste0('.lag',lag)))
}
# Return data frame
return(lagged.data)
}
# ------------------------------------------------------------------------------
# Data split function
# ------------------------------------------------------------------------------
dataSplit <- function(data,size){
# Define dimensions of data split
N 	<- nrow(data)
S   <- 1:N
M 	<- ceiling( size * N )
D 	<- N - M
# Sample the rows according to define dimensions
dimTR <- 1:M
dimTE <- (M+1):N
# Define Training set and test set
trainingSet <- data[dimTR,]
testSet 	<- data[dimTE,]
# Define output list and return it
output <- list( TrainingSet=trainingSet, TestSet=testSet )
# Return output
return(output)
}
# ------------------------------------------------------------------------------
# ------------------------------------------------------------------------------
smv.lag.grid.search <- function( predictor, response, response.name = "SP500" ,lag.array = 1:10,
include.self = TRUE,
gamma.array =  0.5:4, cost.array =  1:10, data.split = 0.99,
inner.trace = FALSE, outer.trace = TRUE, final.trace = TRUE ) {
# Init storage objects
global.mse.svm <- c()
global.gam.svm <- c()
global.cos.svm <- c()
gamma <- gamma.array
cost  <- cost.array
for( h in lag.array ){
ratio.lagged   <- lagged.data.set( h , predictor )
N.ratio.lagged <- nrow(ratio.lagged)
M <- length(response)
index <-  (M - N.ratio.lagged + 1):M
print(N.ratio.lagged)
print(length(index))
data <- as.data.frame( cbind( response[ index ], ratio.lagged ) )
colnames(data)[1] <- response.name
#if(include.self == TRUE){
#  self <- as.data.frame(response)
#  self.lagged <- lagged.data.set(h, self )
#  N.self <- nrow(self.lagged)
#  M.self <- ncol(self.lagged)
#  self.lagged.adjusted <- as.data.frame(2:self.lagged[2:N.self,2:M.self])
#  colnames(self.lagged.adjusted) <- sapply(1:(M.self-1),function(i){
#    paste0("self",i)
#  })
# data <- cbind(data,self.lagged.adjusted)
#}
split      <- dataSplit( data, data.split )
training   <- split$TrainingSet
test       <- split$TestSet
N.training <- nrow( training )
M.training <- ncol( training )
N.test     <- nrow( test )
M.training <- ncol(test)
y.test <- test$SP500
x.test <- test[,setdiff(colnames(test),c(response.name)) ]
# Support Vector Macines (SVM) - Grid Search over Parameters
N.gamma      <- length( gamma )
N.cost       <- length( cost )
model.list   <- list()
name.counter <- 1
mse <- matrix( NA, nrow = N.gamma, ncol = N.cost )
rownames(mse) <- gamma
colnames(mse) <- cost
for( i in 1:N.gamma ){
temp.gamma <- gamma[i]
for( j in 1:N.cost ){
temp.cost <- cost[j]
tempsvm <- svm( SP500 ~.,data = training, scale = FALSE,
kernel = "radial", gamma = temp.gamma, cost = temp.cost,
cross = 0)
temp.prediction <- predict(tempsvm, newx = x.test )
temp.mse <- mean( ( y.test - temp.prediction )**2 )
mse[i,j] <- temp.mse
model.name   <- paste0( "svmGAM",temp.gamma,"COS",temp.cost )
model.list[[name.counter]] <- tempsvm
names( model.list )[name.counter] <- model.name
name.counter <- name.counter + 1
if( inner.trace == TRUE ){
cat("Itteration: i =", i,"/","j =",j,"\n" )
}
}
if( i == N.gamma ){
best.ind   <- which(mse == min(mse), arr.ind = TRUE)
best.gamma <- gamma[best.ind[1]]
best.cost  <- cost[best.ind[2]]
if(outer.trace == TRUE){
cat("\n",
".","\n",
".","\n",
".","\n"
)
Sys.sleep(1)
cat("\n",
"------------------------------------","\n",
"SUB GRID SEARCH FINISHED","\n",
"------------------------------------","\n",
"Number of Lags in Data:", h, "\n",
"Training Observations:", N.training  ,"\n",
"Test Observations:", N.test, "\n",
"BEST PARAMETER SPECIFICATION:","\n",
"GAMMA:",best.gamma,"\n",
"COST:", best.cost, "\n",
"MSE:", mse[best.ind],"\n",
"------------------------------------","\n",
"\n",
"------------------------------------","\n"
)
}
}
}
global.mse.svm <- c(global.mse.svm, min(mse))
global.gam.svm <- c(global.gam.svm, best.gamma)
global.cos.svm <- c(global.cos.svm, best.cost)
}
if( final.trace == TRUE){
h.opt    <- lag.array[which.min( global.mse.svm )]
gam.opt  <- min(global.gam.svm)
cost.opt <- min(global.cos.svm)
mse.opt  <- min(global.mse.svm)
cat("\n",
"************************************","\n",
"------------------------------------","\n",
"FULL GRID SEARCH FINISHED","\n",
"------------------------------------","\n",
"Number of Lags in Data:", h.opt, "\n",
"Training Observations:", N.training  ,"\n",
"Test Observations:", N.test, "\n",
"BEST PARAMETER SPECIFICATION:","\n",
"GAMMA:",gam.opt,"\n",
"COST:", cost.opt, "\n",
"MSE:", mse.opt,"\n",
"------------------------------------","\n",
"\n",
"------------------------------------","\n",
"************************************","\n"
)
}
final.output = list( mse = global.mse.svm, gamma = global.gam.svm, cost = global.cos.svm  )
return( final.output )
}
svm.model <- smv.lag.grid.search(predictor.data,
splog,
response.name = "SP500",
lag.array     = 1:12,
include.self  = FALSE,
gamma.array   = c(seq(0.01,1,0.1),10),
cost.array    = c(seq(0.01,1,0.1),100),
data.split    = 0.80,
inner.trace   = FALSE,
outer.trace   = TRUE,
final.trace   = TRUE
)
ratio.log[is.na(ratio.log)] <- 0
svm.model <- smv.lag.grid.search(ratio.log,
splog,
response.name = "SP500",
lag.array     = 1:3,
include.self  = FALSE,
gamma.array   = c(seq(0.01,1,0.1),10),
cost.array    = c(seq(0.01,1,0.1),100),
data.split    = 0.80,
inner.trace   = FALSE,
outer.trace   = TRUE,
final.trace   = TRUE
)
sentiment.index <- returns( sentiment.index )
sentiment.index <- getSymbols( "UMCSENT" , src = "FRED" , auto.assign = FALSE )
sentiment.index <- returns( sentiment.index )
sentiment.index <- returns( as.data.frame( sentiment.index)  )
N <- nrow(sentiment.index)
# Plot sentiment series
plot( sentiment.index,main = "" )
sentiment.index
sentiment.index
sentiment.index <- getSymbols( "UMCSENT" , src = "FRED" , auto.assign = FALSE )
sentiment.index
returns( as.data.frame( sentiment.index)  )
sentiment.index <- returns( as.data.frame( sentiment.index)  )
plot( sentiment.index,main = "" )
sentiment.index <- getSymbols( "UMCSENT" , src = "FRED" , auto.assign = FALSE )
plot( sentiment.index,main = "" )
sentiment.index <- returns( as.data.frame( sentiment.index)  )
sentiment.acf  <- acf( sentiment.index, plot =FALSE )
plot(sentiment.acf,main="")
sentiment.index <- returns( as.data.frame( sentiment.index)  )
sentiment.acf   <- acf( sentiment.index, plot =FALSE )
png("p3.png")
plot(sentiment.acf,main="")
png("p3.png")
plot(sentiment.acf,main="")
dev.off()
png("p3.png")
plot(sentiment.acf,main="")
dev.off()
sentiment.index <- getSymbols( "UMCSENT" , src = "FRED" , auto.assign = FALSE )
N <- nrow(sentiment.index)
# Plot sentiment series
sentiment.index <- returns( as.data.frame( sentiment.index)  )
sentiment.acf   <- acf( sentiment.index, plot =FALSE )
png("p3.png")
plot(sentiment.acf,main="")
dev.off()
sentiment.pacf <- pacf( sentiment.index )
png("p4.png")
plot(sentiment.pacf,main="")
dev.off()
# ARIMA(1,1,2)
m00 <- auto.arima( sentiment.index, ic = "aic" )
m00
adf.test( sentiment.index )
sentiment.index
adf.test( as.numeric(sentiment.index) )
adf.test( sentiment.index[,1] )
capture.output(adf.test,file="t0.txt")
m02 <- garchFit( UMCSENT ~ arma(1,2) + garch(1, 1), data = sentiment.index, trace = FALSE )
m02
capture.output(m02,file="m02.txt")
adf.test( sentiment.index[,1] )
capture.output(m00,file="m01.txt")
plot(sentiment.index)
sentiment.index
# Get stock data from yahoo finance
symbols      <- c( 'GOOG' )
start        <- "2011-01-01"
end          <- "2015-12-31"
stock.series <- getSymbols( symbols , src = 'yahoo' , from = start , to = end ,auto.assign = FALSE )
dat <- stock.series
df <- as.data.frame(dat)
df$rtrn <- 0
column <- paste(c(sym,".Adjusted"),collapse="")
print(column)
column <- paste(c("GOOG",".Adjusted"),collapse="")
print(column)
for(i in 2:nrow(df)){
df[i,"rtrn"] <- abs(df[i,column]/df[(i-1),column]-1)
}
df$rtrn
returns <- df$rtrn
max.iteration  <- 4
max.lags       <- 5
powers  <- matrix( NA , ncol = ( max.lags + 1 ), nrow = max.iteration )
# Compute ACF
for( i in 1:max.iteration ){
temp.power.return <- returns**i
#temp.power.abs    <- abs(temp.power.return)
temp.acf          <- acf(temp.power.return,plot = FALSE, lag.max = max.lags )$acf
powers[i,]        <- round(temp.acf,4)
}
acf(temp.power.return)
N <- nrow( powers )
M <- ncol( powers )
X <- 1:M
point.shape = 1:N
ymin <- min( powers ) - 0.5
ymax <- max( powers ) + 0.5
plot(X, powers[1,] , type = "b", pch = point.shape[1],
xlab = "Lags", ylab = "Autocorrelation", col = full.color.set[[1]],
ylim = c( -0.1 , ymax ), tck=-0.01 )
for( i in 2:max.iteration){
lines(X, powers[i,] , type = "b", pch = point.shape[i],
xlab = "Lags", ylab = "ACF", col = full.color.set[[i]] )
}
lab01 = expression(paste("|",R[t],"|",sep="") ^1)
lab02 = expression(paste("|",R[t],"|",sep="") ^2)
lab03 = expression(paste("|",R[t],"|",sep="") ^3)
lab04 = expression(paste("|",R[t],"|",sep="") ^4)
#lab05 = expression(paste("|",R[t],"|",sep="") ^5)
legend("topright",
c(lab01,lab02,lab03,lab04),
lty = 1,
col = c(pers.blue,pers.green,pers.red,pers.gray),
pch = point.shape,
cex = 1,
bty = "n",
ncol = 2,
y.intersp = 2,
)
### Styling options
co <- 1/255
pers.green      <- rgb( co *  14 ,  co * 105 , co *  90 )
pers.blue       <- rgb( co *  22 ,  co *  54 , co *  92 )
pers.red        <- rgb( co *  99 ,  co *  37 , co *  35 )
pers.gray       <- rgb( co * 150 ,  co * 150 , co * 150 )
pers.orange     <- rgb( co * 186 ,  co *  85 , co *  59 )
pers.beige      <- rgb( co * 196 ,  co * 189 , co * 151 )
full.color.set  <- list( pers.green , pers.blue, pers.red,
pers.gray, pers.orange, pers.beige
)
plot(X, powers[1,] , type = "b", pch = point.shape[1],
xlab = "Lags", ylab = "Autocorrelation", col = full.color.set[[1]],
ylim = c( -0.1 , ymax ), tck=-0.01 )
for( i in 2:max.iteration){
lines(X, powers[i,] , type = "b", pch = point.shape[i],
xlab = "Lags", ylab = "ACF", col = full.color.set[[i]] )
}
lab01 = expression(paste("|",R[t],"|",sep="") ^1)
lab02 = expression(paste("|",R[t],"|",sep="") ^2)
lab03 = expression(paste("|",R[t],"|",sep="") ^3)
lab04 = expression(paste("|",R[t],"|",sep="") ^4)
#lab05 = expression(paste("|",R[t],"|",sep="") ^5)
legend("topright",
c(lab01,lab02,lab03,lab04),
lty = 1,
col = c(pers.blue,pers.green,pers.red,pers.gray),
pch = point.shape,
cex = 1,
bty = "n",
ncol = 2,
y.intersp = 2,
)
png("p1.png")
plot(X, powers[1,] , type = "b", pch = point.shape[1],
xlab = "Lags", ylab = "Autocorrelation", col = full.color.set[[1]],
ylim = c( -0.1 , ymax ), tck=-0.01 )
for( i in 2:max.iteration){
lines(X, powers[i,] , type = "b", pch = point.shape[i],
xlab = "Lags", ylab = "ACF", col = full.color.set[[i]] )
}
lab01 = expression(paste("|",R[t],"|",sep="") ^1)
lab02 = expression(paste("|",R[t],"|",sep="") ^2)
lab03 = expression(paste("|",R[t],"|",sep="") ^3)
lab04 = expression(paste("|",R[t],"|",sep="") ^4)
#lab05 = expression(paste("|",R[t],"|",sep="") ^5)
legend("topright",
c(lab01,lab02,lab03,lab04),
lty = 1,
col = c(pers.blue,pers.green,pers.red,pers.gray),
pch = point.shape,
cex = 1,
bty = "n",
ncol = 2,
y.intersp = 2,
)
dev.off()
full.color.set[[1]]
png("p1.png")
plot(X, powers[1,] , type = "b", pch = point.shape[1],
xlab = "Lags", ylab = "Autocorrelation", col = full.color.set[[1]],
ylim = c( -0.1 , ymax ), tck=-0.01 )
for( i in 2:max.iteration){
lines(X, powers[i,] , type = "b", pch = point.shape[i],
xlab = "Lags", ylab = "ACF", col = full.color.set[[i]] )
}
lab01 = expression(paste("|",R[t],"|",sep="") ^1)
lab02 = expression(paste("|",R[t],"|",sep="") ^2)
lab03 = expression(paste("|",R[t],"|",sep="") ^3)
lab04 = expression(paste("|",R[t],"|",sep="") ^4)
#lab05 = expression(paste("|",R[t],"|",sep="") ^5)
legend("topright",
c(lab01,lab02,lab03,lab04),
lty = 1,
col = c(pers.green,pers.blue,pers.red,pers.gray),
pch = point.shape,
cex = 1,
bty = "n",
ncol = 2,
y.intersp = 2,
)
dev.off()
dat <- read.csv( "SP500_shiller.csv" )
# Get price and dividend data
real.dividend <- dat$Real.Dividend
real.price    <- dat$Real.Price
M             <- length( real.dividend )
sp500         <- dat$SP500
pe10          <- dat$P.E10
# Compute ratio series
ratio     <- ( real.dividend / real.price )
ratio.log <- as.data.frame(returns( ratio ,log = TRUE, center = TRUE ) )
splog     <- as.data.frame(returns(sp500,log=TRUE,center=FALSE) )
splog     <- splog[,1]
pe10log   <- as.data.frame(returns(pe10,log=TRUE,center=FALSE) )
len       <- length(splog)
localH2O      <- h2o.init(ip = "localhost", port = 54321, startH2O = TRUE)
# Construct training and test data
lag.response  <- lagged.data.set(10,as.data.frame(splog) )
lag.predictor <- lagged.data.set(10,as.data.frame(ratio.log) )
N01           <- nrow(lag.response)
M01           <- ncol(lag.response)
N02           <- nrow(lag.predictor)
M02           <- ncol(lag.predictor)
resp          <- splog[(M  -N02+1):M  ]
full.data     <- cbind(resp,lag.response[,2:M01],lag.predictor)
split.data    <- dataSplit(full.data,0.80)
# Map to H20 data frame
training.h20  <- as.h2o(split.data$TrainingSet, destination_frame = "Training")
test.h20      <- as.h2o(split.data$TestSet, destination_frame = "Test")
m01 <- h2o.deeplearning(x = 2:M01,
y = 1,
training_frame   = training.h20,
validation_frame = test.h20,
activation       = "Tanh",
input_dropout_ratio   = 0.2,
hidden_dropout_ratios = c(0.5,0.5,0.5,0.5),
hidden = c(100,100,100,100),
epochs = 300,
shuffle_training_data = FALSE
)
m01
